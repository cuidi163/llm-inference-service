# LLM Inference Service (Golang + vLLM)

A high-performance backend for large language model inference, built with Golang and designed for scalability.